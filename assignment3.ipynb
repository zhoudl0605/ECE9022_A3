{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import BloodMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import VGG16_Weights\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Select device to accelerate the computation\n",
    "#check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#check if MPS is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_dataset = BloodMNIST(\n",
    "    root='./datasets/', split='train', download=True, transform=transform)\n",
    "val_dataset = BloodMNIST(root='./datasets/', split='val',\n",
    "                         download=True, transform=transform)\n",
    "test_dataset = BloodMNIST(root='./datasets/', split='test',\n",
    "                          download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Data Loaders\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lable: [7]\n",
      "Image size: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# get sample data\n",
    "sample, label = train_dataset[0]\n",
    "print(f\"Lable: {label}\")\n",
    "print(f\"Image size: {sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg16_model():\n",
    "    # Load pre-trained VGG16 model\n",
    "    model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "    # Remove the existing classification head by replacing it\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 4096),  # First fully connected layer (unchanged)\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 256),  # Replace second FC layer with smaller one\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, 8),  # Binary classification (fracture vs. non-fracture)\n",
    "        nn.Softmax(dim=1)  # Softmax for classification\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb_image_np(gray_image_np):\n",
    "    return np.dstack([gray_image_np, gray_image_np, gray_image_np])\n",
    "\n",
    "\n",
    "def to_rgb_image_nps(gray_image_nps):\n",
    "    for i in range(len(gray_image_nps)):\n",
    "        gray_image_nps[i] = to_rgb_image_np(gray_image_nps[i])\n",
    "    return gray_image_nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer=None, class_criterion=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training batch\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = class_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate(model, dataloader, class_criterion=None):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation batch\", leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.squeeze().long().to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = class_criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Testing batch\", leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.squeeze().long().to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "\n",
    "    # calculate accuracy, precision, recall, and F1 score\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c12db0fe9849c2af484cc97b9310c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467714b791714900b46476835a03867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batch:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55765ad483b24367b098a4d0815b3474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batch:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4816272a984f4a31a8124487858384c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batch:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8ec5d0abee4146813a2f507fa5a25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batch:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939e18ce5c024b99b5900458e4a36607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batch:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8a5db8782d4f8d85164ff4a7e73028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batch:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3422e2ffdd5b4f5eac937b62a88a4386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batch:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953dc155b3064372bfad264d03857c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batch:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train VGG16\n",
    "# Use Cross-Entropy Loss and Adam optimizer.\n",
    "model = get_vgg16_model()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "early_stop = 5\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "min_val_loss = np.inf\n",
    "early_stop_counter = 0\n",
    "\n",
    "# use tqdm for progress bar\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n",
    "    # Train for one epoch\n",
    "    train_loss_epoch = train(\n",
    "        model, train_loader, optimizer, criterion)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "\n",
    "    # Validate on validation set\n",
    "    val_loss_epoch = validate(model, val_loader, criterion)\n",
    "    val_loss.append(val_loss_epoch)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss_epoch < min_val_loss:\n",
    "        min_val_loss = val_loss_epoch\n",
    "        early_stop_counter = 0\n",
    "        best_model = model.state_dict()\n",
    "        # Save the model\n",
    "        torch.save(best_model, \"best_model_task_1.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model.load_state_dict(\"best_model_task_1.pth\")\n",
    "model.eval()\n",
    "test_loss, test_accuracy = validate(model, test_loader, criterion)\n",
    "\n",
    "# calculate accuracy, precision, recall, and F1 score\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Erosion(image):\n",
    "    kernel = np.ones((3, 3), np.uint8)  # 3x3 结构元素\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def Skeletonization(image):\n",
    "    skel = np.zeros(image.shape, np.uint8)  # 骨架结果初始化\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)  # 二值化\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))  # 交叉形结构元素\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        eroded = cv2.erode(image, element)  # 腐蚀\n",
    "        temp = cv2.dilate(eroded, element)  # 先腐蚀再膨胀 (开运算)\n",
    "        temp = cv2.subtract(image, temp)  # 提取去掉的部分\n",
    "        skel = cv2.bitwise_or(skel, temp)  # 累加骨架\n",
    "        image = eroded.copy()\n",
    "\n",
    "        if cv2.countNonZero(image) == 0:  # 如果图像完全腐蚀完毕，停止\n",
    "            done = True\n",
    "\n",
    "    return skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErosionTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image):\n",
    "        print(f\"image type: {image.mode}\")\n",
    "        # 1. 将图像转换为灰度图像\n",
    "        gray_image = image.convert(\"L\")  # 'L'模式表示灰度图像\n",
    "\n",
    "        # 2. 应用形态学操作 (例如膨胀操作)\n",
    "        gray_image_np = np.array(gray_image)\n",
    "        gray_image_np = cv2.dilate(\n",
    "            gray_image_np, None, iterations=1)  # 膨胀操作，可根据需要调整\n",
    "\n",
    "        # 3. 将灰度图像复制成3通道\n",
    "        rgb_image_np = np.dstack(\n",
    "            [gray_image_np, gray_image_np, gray_image_np])  # 复制单通道成3通道\n",
    "\n",
    "        # 4. 将RGB图像转换为PIL图像\n",
    "        rgb_image = Image.fromarray(rgb_image_np)\n",
    "\n",
    "        return rgb_image\n",
    "    \n",
    "class SkeletonizationTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # 1. 将图像转换为灰度图像\n",
    "        gray_image = image.convert(\"L\")  # 'L'模式表示灰度图像\n",
    "\n",
    "        # 2. 应用形态学操作 (例如骨架化操作)\n",
    "        gray_image_np = np.array(gray_image)\n",
    "        gray_image_np = Skeletonization(gray_image_np)\n",
    "        \n",
    "        # 3. 将灰度图像复制成3通道\n",
    "        rgb_image_np = np.dstack(\n",
    "            [gray_image_np, gray_image_np, gray_image_np])  # 复制单通道成3通道\n",
    "\n",
    "        # 4. 将RGB图像转换为PIL图像\n",
    "        rgb_image = Image.fromarray(rgb_image_np)\n",
    "\n",
    "        return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trasnform = transforms.Compose([\n",
    "    ErosionTransform(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_dataset = BloodMNIST(\n",
    "    root='./datasets/', split='train', download=True, transform=transform)\n",
    "val_dataset = BloodMNIST(root='./datasets/', split='val',\n",
    "                         download=True, transform=transform)\n",
    "test_dataset = BloodMNIST(root='./datasets/', split='test',\n",
    "                          download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VGG16\n",
    "# Use Cross-Entropy Loss and Adam optimizer.\n",
    "model = get_vgg16_model()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "early_stop = 5\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "min_val_loss = np.inf\n",
    "early_stop_counter = 0\n",
    "\n",
    "# use tqdm for progress bar\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n",
    "    # Train for one epoch\n",
    "    train_loss_epoch = train(\n",
    "        model, train_loader, optimizer, criterion)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "\n",
    "    # Validate on validation set\n",
    "    val_loss_epoch = validate(model, val_loader, criterion)\n",
    "    val_loss.append(val_loss_epoch)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss_epoch < min_val_loss:\n",
    "        min_val_loss = val_loss_epoch\n",
    "        early_stop_counter = 0\n",
    "        best_model = model.state_dict()\n",
    "        # Save the model\n",
    "        torch.save(best_model, \"best_model_task_2.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model.load_state_dict(\"best_model_task_2.pth\")\n",
    "model.eval()\n",
    "test_loss, test_accuracy = validate(model, test_loader, criterion)\n",
    "\n",
    "# calculate accuracy, precision, recall, and F1 score\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trasnform = transforms.Compose([\n",
    "    SkeletonizationTransform(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_dataset = BloodMNIST(\n",
    "    root='./datasets/', split='train', download=True, transform=transform)\n",
    "val_dataset = BloodMNIST(root='./datasets/', split='val',\n",
    "                         download=True, transform=transform)\n",
    "test_dataset = BloodMNIST(root='./datasets/', split='test',\n",
    "                          download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VGG16\n",
    "# Use Cross-Entropy Loss and Adam optimizer.\n",
    "model = get_vgg16_model()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "early_stop = 5\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "min_val_loss = np.inf\n",
    "early_stop_counter = 0\n",
    "\n",
    "# use tqdm for progress bar\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n",
    "    # Train for one epoch\n",
    "    train_loss_epoch = train(\n",
    "        model, train_loader, optimizer, criterion)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "\n",
    "    # Validate on validation set\n",
    "    val_loss_epoch = validate(model, val_loader, criterion)\n",
    "    val_loss.append(val_loss_epoch)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss_epoch < min_val_loss:\n",
    "        min_val_loss = val_loss_epoch\n",
    "        early_stop_counter = 0\n",
    "        best_model = model.state_dict()\n",
    "        # Save the model\n",
    "        torch.save(best_model, \"best_model_task_2.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model.load_state_dict(\"best_model_task_2.pth\")\n",
    "model.eval()\n",
    "test_loss, test_accuracy = validate(model, test_loader, criterion)\n",
    "\n",
    "# calculate accuracy, precision, recall, and F1 score\n",
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
