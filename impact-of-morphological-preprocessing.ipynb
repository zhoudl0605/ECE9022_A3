{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7539891,"sourceType":"datasetVersion","datasetId":4390240}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install medmnist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:32.673264Z","iopub.execute_input":"2025-03-27T16:45:32.673707Z","iopub.status.idle":"2025-03-27T16:45:40.064560Z","shell.execute_reply.started":"2025-03-27T16:45:32.673676Z","shell.execute_reply":"2025-03-27T16:45:40.063579Z"}},"outputs":[{"name":"stdout","text":"Collecting medmnist\n  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\nCollecting fire (from medmnist)\n  Downloading fire-0.7.0.tar.gz (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\nDownloading medmnist-3.0.2-py3-none-any.whl (25 kB)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=8d16ade0354dd66c8b0397eed57a06dde883cc37a8536a9829932af90c83dd49\n  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\nSuccessfully built fire\nInstalling collected packages: fire, medmnist\nSuccessfully installed fire-0.7.0 medmnist-3.0.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from medmnist import BloodMNIST\nimport matplotlib.pyplot as plt\nfrom torchvision import models\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import VGG16_Weights\nimport cv2\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:40.065998Z","iopub.execute_input":"2025-03-27T16:45:40.066236Z","iopub.status.idle":"2025-03-27T16:45:47.784285Z","shell.execute_reply.started":"2025-03-27T16:45:40.066216Z","shell.execute_reply":"2025-03-27T16:45:47.783553Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Select device to accelerate the computation\n#check if CUDA is available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#check if MPS is available\ndevice = torch.device(\"mps\" if torch.backends.mps.is_available() else device)\n\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:47.786346Z","iopub.execute_input":"2025-03-27T16:45:47.786843Z","iopub.status.idle":"2025-03-27T16:45:47.857196Z","shell.execute_reply.started":"2025-03-27T16:45:47.786818Z","shell.execute_reply":"2025-03-27T16:45:47.856102Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntrain_dataset = BloodMNIST(\n    root='/kaggle/input/standardized-biomedical-images-medmnist', split='train', download=False, transform=transform)\nval_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='val',\n                         download=False, transform=transform)\ntest_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='test',\n                          download=False, transform=transform)\n\n\n# Data Loaders\nbatch_size = 128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:47.859253Z","iopub.execute_input":"2025-03-27T16:45:47.859609Z","iopub.status.idle":"2025-03-27T16:45:48.864382Z","shell.execute_reply.started":"2025-03-27T16:45:47.859582Z","shell.execute_reply":"2025-03-27T16:45:48.863669Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# get sample data\nsample, label = train_dataset[0]\nprint(f\"Lable: {label}\")\nprint(f\"Image size: {sample.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:48.865231Z","iopub.execute_input":"2025-03-27T16:45:48.865511Z","iopub.status.idle":"2025-03-27T16:45:48.943211Z","shell.execute_reply.started":"2025-03-27T16:45:48.865464Z","shell.execute_reply":"2025-03-27T16:45:48.941721Z"}},"outputs":[{"name":"stdout","text":"Lable: [7]\nImage size: torch.Size([3, 224, 224])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def get_vgg16_model():\n    # Load pre-trained VGG16 model\n    model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n    # Remove the existing classification head by replacing it\n    model.classifier = nn.Sequential(\n        nn.Linear(25088, 4096),  # First fully connected layer (unchanged)\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(4096, 256),  # Replace second FC layer with smaller one\n        nn.ReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(256, 8),  # 8-class classification \n        # nn.Softmax(dim=1)  # Softmax for classification\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:48.944061Z","iopub.execute_input":"2025-03-27T16:45:48.944288Z","iopub.status.idle":"2025-03-27T16:45:48.948843Z","shell.execute_reply.started":"2025-03-27T16:45:48.944268Z","shell.execute_reply":"2025-03-27T16:45:48.947773Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def to_rgb_image_np(gray_image_np):\n    return np.dstack([gray_image_np, gray_image_np, gray_image_np])\n\n\ndef to_rgb_image_nps(gray_image_nps):\n    for i in range(len(gray_image_nps)):\n        gray_image_nps[i] = to_rgb_image_np(gray_image_nps[i])\n    return gray_image_nps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:48.949832Z","iopub.execute_input":"2025-03-27T16:45:48.950140Z","iopub.status.idle":"2025-03-27T16:45:48.969007Z","shell.execute_reply.started":"2025-03-27T16:45:48.950108Z","shell.execute_reply":"2025-03-27T16:45:48.968204Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train(model, dataloader, optimizer=None, class_criterion=None):\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(dataloader, desc=\"Training batch\", leave=False):\n        images = images.to(device)\n        labels = labels.view(-1).long().to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        \n        loss = class_criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()* images.size(0)\n    return running_loss / len(dataloader.dataset)\n\n\ndef validate(model, dataloader, class_criterion=None):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validation batch\", leave=False):\n            images = images.to(device)\n            labels = labels.view(-1).long().to(device)\n\n            outputs = model(images)\n            loss = class_criterion(outputs, labels)\n            running_loss += loss.item()* images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return running_loss / len(dataloader.dataset)\n\ndef test(model, dataloader, class_criterion=None):\n    model.eval()\n    y_true, y_pred = [], []\n    running_loss = 0.0\n    first_run = True\n    show_sample = True\n\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Testing batch\", leave=False):\n            images = images.to(device)\n            labels = labels.view(-1).long().to(device)\n\n            outputs = model(images)\n            loss = class_criterion(outputs, labels) if class_criterion else 0.0\n            \n            running_loss += loss.item() * labels.size(0)\n            \n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(outputs.argmax(dim=1).cpu().numpy())\n\n            if show_sample:\n                count = 0\n                # print the sample of misclassified images\n                for i in range(len(labels)):\n                    if labels[i] != outputs.argmax(dim=1)[i]:\n                        print(\n                            f\"True: {labels[i].item()}, Predicted: {outputs.argmax(dim=1)[i].item()}\")\n                        plt.imshow(images[i].cpu().permute(1, 2, 0))\n                        plt.show()\n                        count += 1\n                        if count == 3:\n                            show_sample = False\n                            break\n\n    # 计算指标\n    acc = accuracy_score(y_true, y_pred) * 100\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n    avg_loss = running_loss / len(dataloader.dataset)\n\n\n    print(f\"Accuracy: {acc:.2f}%\")\n    print(f\"Precision: {precision:.2f}\")\n    print(f\"Recall: {recall:.2f}\")\n    print(f\"F1 Score: {f1:.2f}\")\n    print(f\"Average Loss: {avg_loss:.4f}\")\n\n    # 结果字典\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'loss': avg_loss\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:48.969863Z","iopub.execute_input":"2025-03-27T16:45:48.970140Z","iopub.status.idle":"2025-03-27T16:45:48.986345Z","shell.execute_reply.started":"2025-03-27T16:45:48.970116Z","shell.execute_reply":"2025-03-27T16:45:48.985518Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Train VGG16\n# Use Cross-Entropy Loss and Adam optimizer.\nmodel = get_vgg16_model()\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=25,  # maximum number of epochs\n    eta_min=1e-5  # minimum learning rate\n)\nepochs = 25\nearly_stop = 5\ntrain_loss = []\nval_loss = []\nmin_val_loss = np.inf\nearly_stop_counter = 0\nbest_model = None\n\n# use tqdm for progress bar\nfor epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n    # Train for one epoch\n    train_loss_epoch = train(\n        model, train_loader, optimizer, criterion)\n    train_loss.append(train_loss_epoch)\n\n    # Validate on validation set\n    val_loss_epoch = validate(model, val_loader, criterion)\n    val_loss.append(val_loss_epoch)\n\n    scheduler.step()\n    # Early stopping logic\n    if val_loss_epoch < min_val_loss:\n        min_val_loss = val_loss_epoch\n        early_stop_counter = 0\n        best_model = model.state_dict()\n        # Save the model\n    else:\n        early_stop_counter += 1\n\n    if early_stop_counter >= early_stop:\n        print(f\"Early stopping at epoch {epoch}\")\n        break\n\n# Plot the results\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:45:48.988824Z","iopub.execute_input":"2025-03-27T16:45:48.989087Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 192MB/s]  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5934b52149884622bfcc46a4246f955b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation batch:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training batch:   0%|          | 0/94 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b764b160244e77b3179e40a18559ea"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# test model\nmodel.load_state_dict(best_model)\nmodel.eval()\n\n# calculate accuracy, precision, recall, and F1 score\ntest(model, test_loader, criterion)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Skeletonization(image):\n    skel = np.zeros(image.shape, np.uint8) \n    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY) \n    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n    done = False\n\n    while not done:\n        eroded = cv2.erode(image, element) \n        temp = cv2.dilate(eroded, element) \n        temp = cv2.subtract(image, temp) \n        skel = cv2.bitwise_or(skel, temp) \n        image = eroded.copy()\n\n        if cv2.countNonZero(image) == 0: \n            done = True\n\n    return skel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_erosion = True\nclass ErosionTransform:\n    def __init__(self):\n        pass\n\n    def __call__(self, image):\n        print(f\"image type: {image.mode}\")\n        if first_erosion:\n            plt.imshow(image)\n            plt.show()\n        gray_image = image.convert(\"L\")\n\n        gray_image_np = np.array(gray_image)\n        gray_image_np = cv2.erodes(\n            gray_image_np, None, iterations=1)\n\n        rgb_image_np = np.dstack(\n            [gray_image_np, gray_image_np, gray_image_np])\n\n        rgb_image = Image.fromarray(rgb_image_np)\n        if first_erosion:\n            plt.imshow(rgb_image)\n            plt.show()\n            first_erosion = False\n\n        return rgb_image\n\n\nfirst_skeletonization = True\nclass SkeletonizationTransform:\n    def __init__(self):\n        pass\n\n    def __call__(self, image):\n        if first_skeletonization:\n            plt.imshow(image)\n            plt.show()\n        \n        gray_image = image.convert(\"L\")\n\n        gray_image_np = np.array(gray_image)\n        gray_image_np = Skeletonization(gray_image_np)\n\n        rgb_image_np = np.dstack(\n            [gray_image_np, gray_image_np, gray_image_np])\n\n        rgb_image = Image.fromarray(rgb_image_np)\n        if first_skeletonization:\n            plt.imshow(rgb_image)\n            plt.show()\n            first_skeletonization = False\n\n        return rgb_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trasnform = transforms.Compose([\n    ErosionTransform(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntrain_dataset = BloodMNIST(\n    root='/kaggle/input/standardized-biomedical-images-medmnist', split='train', download=False, transform=transform)\nval_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='val',\n                         download=False, transform=transform)\ntest_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='test',\n                          download=False, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train VGG16\n# Use Cross-Entropy Loss and Adam optimizer.\nmodel = get_vgg16_model()\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=25,  # maximum number of epochs\n    eta_min=1e-5  # minimum learning rate\n)\nepochs = 25\nearly_stop = 5\ntrain_loss = []\nval_loss = []\nmin_val_loss = np.inf\nearly_stop_counter = 0\nbest_model = None\n\n# use tqdm for progress bar\nfor epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n    # Train for one epoch\n    train_loss_epoch = train(\n        model, train_loader, optimizer, criterion)\n    train_loss.append(train_loss_epoch)\n\n    # Validate on validation set\n    val_loss_epoch = validate(model, val_loader, criterion)\n    val_loss.append(val_loss_epoch)\n    scheduler.step()\n\n    # Early stopping logic\n    if val_loss_epoch < min_val_loss:\n        min_val_loss = val_loss_epoch\n        early_stop_counter = 0\n        best_model = model.state_dict()\n    else:\n        early_stop_counter += 1\n\n    if early_stop_counter >= early_stop:\n        print(f\"Early stopping at epoch {epoch}\")\n        break\n\n# Plot the results\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test model\nmodel.load_state_dict(best_model)\nmodel.eval()\n\n# calculate accuracy, precision, recall, and F1 score\ntest(model, test_loader, criterion)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trasnform = transforms.Compose([\n    SkeletonizationTransform(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntrain_dataset = BloodMNIST(\n    root='/kaggle/input/standardized-biomedical-images-medmnist', split='train', download=False, transform=transform)\nval_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='val',\n                         download=False, transform=transform)\ntest_dataset = BloodMNIST(root='/kaggle/input/standardized-biomedical-images-medmnist', split='test',\n                          download=False, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train VGG16\n# Use Cross-Entropy Loss and Adam optimizer.\nmodel = get_vgg16_model()\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=25,  # maximum number of epochs\n    eta_min=1e-5  # minimum learning rate\n)\nepochs = 25\nearly_stop = 5\ntrain_loss = []\nval_loss = []\nmin_val_loss = np.inf\nearly_stop_counter = 0\nbest_model = None\n\n# use tqdm for progress bar\nfor epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True):\n    # Train for one epoch\n    train_loss_epoch = train(\n        model, train_loader, optimizer, criterion)\n    train_loss.append(train_loss_epoch)\n\n    # Validate on validation set\n    val_loss_epoch = validate(model, val_loader, criterion)\n    val_loss.append(val_loss_epoch)\n    scheduler.step()\n    \n    # Early stopping logic\n    if val_loss_epoch < min_val_loss:\n        min_val_loss = val_loss_epoch\n        early_stop_counter = 0\n        best_model = model.state_dict()\n    else:\n        early_stop_counter += 1\n\n    if early_stop_counter >= early_stop:\n        print(f\"Early stopping at epoch {epoch}\")\n        break\n\n# Plot the results\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test model\nmodel.load_state_dict(best_model)\nmodel.eval()\n\n# calculate accuracy, precision, recall, and F1 score\ntest(model, test_loader, criterion)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}